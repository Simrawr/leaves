{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVTyPToX3m72+A5gDYSOjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Simrawr/leaves/blob/main/leaf_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yapsxI_Wo0Nv",
        "outputId": "229f3c2e-5576-4e36-827d-3f8751715235"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyIvTBFApsb2",
        "outputId": "af1658cf-72e2-4302-982d-dcc287d668ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lA0QqvHrcmmy"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "data_dir = \"data2/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data2.zip"
      ],
      "metadata": {
        "id": "WrqKK1MsdCN0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653b504b-1d95-4612-d142-e9820d408ec6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data2.zip\n",
            "replace __MACOSX/._data2? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(data_dir + '/train')\n",
        "val_data = datasets.ImageFolder(data_dir + '/val')"
      ],
      "metadata": {
        "id": "t6j4eavsnwCw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30), #data augumnetation\n",
        "                                       transforms.RandomResizedCrop(224),#resize\n",
        "                                       transforms.RandomHorizontalFlip(), #data augumnetation\n",
        "                                       transforms.ToTensor()])\n",
        "val_transforms = transforms.Compose([transforms.RandomResizedCrop(224), #resize\n",
        "                                      transforms.ToTensor()])\n",
        "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
        "val_data = datasets.ImageFolder(data_dir + '/val', transform=val_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_data, batch_size=8)\n",
        "dataiter = iter(train_loader)\n",
        "images, classes  = next(dataiter)\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(classes.shape)"
      ],
      "metadata": {
        "id": "4KrH9G81n0Qq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc4ad39-7ad7-443e-bcdf-4f59260b0e2c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "torch.Size([8, 3, 224, 224])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "class CropDetectCNN(nn.Module):\n",
        "    # initialize the class and the parameters\n",
        "    def __init__(self):\n",
        "        super(CropDetectCNN, self).__init__()\n",
        "\n",
        "        # convolutional layer 1 & max pool layer 1\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        # convolutional layer 2 & max pool layer 2\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1, stride=2),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "\n",
        "        #Fully connected layer\n",
        "        self.fc = nn.Linear(32*28*28, 39)\n",
        "\n",
        "    # Feed forward the network\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "model = CropDetectCNN()\n",
        "print(model)"
      ],
      "metadata": {
        "id": "fam8HQk5sgCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79b8b3f-bc06-4a61-bede-8bc0eb6d7ea8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CropDetectCNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Linear(in_features=25088, out_features=39, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "7JxGCAmfsmoi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "6MavrS6IsrBo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 # run more iterations\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, classes in train_loader:\n",
        "        # To device - to transfrom the image and classes to CPU|GPU\n",
        "        images, classes = images.to(device), classes.to(device)\n",
        "\n",
        "        # clears old gradients from the last step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # train the images\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "        #calculate the loss given the outputs and the classes\n",
        "        loss = criterion(outputs, classes)\n",
        "\n",
        "        # compute the loss of every parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # apply the optimizer and its parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        #update the loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    else:\n",
        "        validation_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        # to make the model run faster we are using the gradients on the train\n",
        "        with torch.no_grad():\n",
        "            # specify that this is validation and not training\n",
        "            model.eval()\n",
        "            for images, classes in val_loader:\n",
        "                # Use GPU\n",
        "                images, classes = images.to(device), classes.to(device)\n",
        "\n",
        "                # validate the images\n",
        "                outputs = model(images)\n",
        "\n",
        "                # compute validation loss\n",
        "                loss = criterion(outputs, classes)\n",
        "\n",
        "                #update loss\n",
        "                validation_loss += loss.item()\n",
        "\n",
        "                # get the exponential of the outputs\n",
        "                ps = torch.exp(outputs)\n",
        "\n",
        "                #Returns the k largest elements of the given input tensor along a given dimension.\n",
        "                top_p, top_class = ps.topk(1, dim=1)\n",
        "\n",
        "                # reshape the tensor\n",
        "                equals = top_class == classes.view(*top_class.shape)\n",
        "\n",
        "                # calculate the accuracy.\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "        # change the mode to train for the next epochs\n",
        "        model.train()\n",
        "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Valid Loss: {:.3f}.. \".format(validation_loss/len(val_loader)),\n",
        "              \"Valid Accuracy: {:.3f}\".format(accuracy/len(val_loader)))"
      ],
      "metadata": {
        "id": "eMw6mYX2tFdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "a6a0343c-bb5d-47d4-a16a-1e1a26c65144"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f621dcf69344>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# To device - to transfrom the image and classes to CPU|GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# clears old gradients from the last step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "FqJfs93gqIHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1cbfdf7-e447-4ed6-a7c7-1f6d5f305c53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.class_to_idx = train_data.class_to_idx\n",
        "model.class_to_idx.items()"
      ],
      "metadata": {
        "id": "923hjuPnOBY7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55187c3-590d-429c-9999-6df8f9937b56"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('apple Cassava', 0), ('apple black rot', 1), ('apple scab', 2), ('cedar apple rust', 3), ('cherry healthy', 4), ('cherry powdery mildew', 5), ('corn cercospora leaf spot gray leaf spot', 6), ('corn common rust', 7), ('corn healthy', 8), ('corn northern leaf blight', 9), ('grape black rot', 10), ('grape esca (black measles)', 11), ('grape healthy', 12), ('grape leaf blight (isariopsis leaf spot)', 13), ('healthy', 14), ('orange haunglongbing (citrus greening)', 15), ('peach bacterial spot', 16), ('peach healthy', 17), ('pepper bacterial spot', 18), ('pepper healthy', 19), ('potato early blight', 20), ('potato healthy', 21), ('potato late blight', 22), ('rice BrownSpot', 23), ('rice Healthy', 24), ('rice Hispa', 25), ('rice LeafBlast', 26), ('squash powdery mildew', 27), ('strawberry healthy', 28), ('strawberry leaf scorch', 29), ('tomato bacterial spot', 30), ('tomato early blight', 31), ('tomato healthy', 32), ('tomato late blight', 33), ('tomato leaf mold', 34), ('tomato mosaic virus', 35), ('tomato septoria leaf spot', 36), ('tomato spider mites two-spotted spider mite', 37), ('tomato target spot', 38), ('tomato yellow leaf curl virus', 39)])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}